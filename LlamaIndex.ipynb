{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pavan3008/LlamaIndex-Talk-to-your-doc/blob/main/LlamaIndex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nW_0yKusLRWK"
      },
      "outputs": [],
      "source": [
        "!pip install -q llama-index\n",
        "!pip install -q openai\n",
        "!pip install -q transformers\n",
        "!pip install -q accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\""
      ],
      "metadata": {
        "id": "wwiMDG-2Z3je"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms import OpenAI\n",
        "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
        "from IPython.display import Markdown, display"
      ],
      "metadata": {
        "id": "bwdh1lj6g_pz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = SimpleDirectoryReader(\"data\").load_data()"
      ],
      "metadata": {
        "id": "y0hb-49phJj0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = VectorStoreIndex.from_documents(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7oTIw4YhJqD",
        "outputId": "1089f7e2-595c-4f9e-e00e-1c8e252dd676"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /tmp/llama_index...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_query_engine()\n"
      ],
      "metadata": {
        "id": "PjC2iTmhhJzU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What did pavan do as graduate teaching assistant? \")"
      ],
      "metadata": {
        "id": "UGCwgL2Ng_s1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(f\"<b>{response}</b>\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "xF8Yk2-rg_wQ",
        "outputId": "f001c097-c51e-46ec-840a-df6db3ccf62c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<b>As a graduate teaching assistant, Pavan had the privilege of working on a full-stack exercise tracker application, where he developed the front-end using React and the back end with Python/Django. Through this project, he improved application performance by 10% and contributed to reducing manual reporting efforts by 12 hours per week.</b>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Storing and Loading the Index"
      ],
      "metadata": {
        "id": "JNVgRgycmlYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index.storage_context.persist()"
      ],
      "metadata": {
        "id": "3bjDrdRag_3Q"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import StorageContext, load_index_from_storage\n",
        "\n",
        "storage_context = StorageContext.from_defaults(persist_dir=\"./storage\")\n",
        "index = load_index_from_storage(storage_context=storage_context)"
      ],
      "metadata": {
        "id": "YjcYRoSlhAAS"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nTn8d9UGhALZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How to Customize"
      ],
      "metadata": {
        "id": "jLO4x48IoHTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import ServiceContext, set_global_service_context\n"
      ],
      "metadata": {
        "id": "nfDyiWy1Z3m1"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define LLM: https://gpt-index.readthedocs.io/en/latest/core_modules/model_modules/llms/usage_custom.html\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0, max_tokens=256)\n",
        "\n",
        "# configure service context\n",
        "service_context = ServiceContext.from_defaults(llm=llm, chunk_size=800, chunk_overlap=20)\n",
        "# set_global_service_context(service_context)\n",
        "index = VectorStoreIndex.from_documents(documents, service_context=service_context)"
      ],
      "metadata": {
        "id": "q4t_HpOAZ3qL"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from llama_index.llms import PaLM\n",
        "# service_context = ServiceContext.from_defaults(llm=PaLM())"
      ],
      "metadata": {
        "id": "MunTVWILl7Bv"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_query_engine(streaming=True)\n",
        "response = query_engine.query(\"What did the pavan do at Landmark group?\")\n",
        "response.print_response_stream()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTVyuuZcl7E3",
        "outputId": "1e23f7de-e10e-44e0-8071-f066ddb45823"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At Landmark Group, Pavan worked as a Software Engineer."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RdrxRhhPl7IB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_chat_engine()\n",
        "response = query_engine.chat(\"What did Pavan do?\")\n",
        "display(Markdown(f\"<b>{response}</b>\"))"
      ],
      "metadata": {
        "id": "V9uzsIaxl7Lr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "12ba5c9f-eaf6-418c-81d8-791943c5df06"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<b>Pavan has done several things. Some of his notable achievements include:\n\n1. Developing a front-end for a full-stack exercise tracker application using React.\n2. Developing the back end of the application using Python/Django.\n3. Migrating an application from Laravel to FastAPI.\n4. Optimizing AWS cloud resources and AWS RDS.\n5. Identifying and resolving security threats using AI/ML algorithms.\n6. Developing a responsive GenAI application.\n7. Enhancing PDF document processing with LlamaIndex.\n8. Creating a travel planning iOS application using SwiftUI.\n\nThese are just a few examples of what Pavan has done. He has a diverse range of skills and experiences in software development and has worked on various projects.</b>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "06TRYc4Pl7SE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using a HuggingFace LLM\n",
        "\n",
        "This will NOT work on the Free Google Colab. You will need colab Pro. Video on the quantized models is coming soon....."
      ],
      "metadata": {
        "id": "7KLRgszMrAT5"
      }
    }
  ]
}